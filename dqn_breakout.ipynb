{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn_breakout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arem77/Colab/blob/master/dqn_breakout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0kV3fK6sxU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5c40666-4da2-4258-8e60-f0386e5d436a"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoXmeBKHsUQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8b30feb0-a1ae-43e9-d8a9-13d3b06c4115"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import gym\n",
        "\n",
        "from collections import deque\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.losses import huber_loss\n",
        "from tensorboardcolab import *\n",
        "\n",
        "from gym import envs\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gze8t1QWtahw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "outputId": "9b78a3c7-e760-4c0f-b4ba-21d5ae4d5f50"
      },
      "source": [
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "Suggested packages:\n",
            "  libgle3\n",
            "The following NEW packages will be installed:\n",
            "  python-opengl\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 496 kB of archives.\n",
            "After this operation, 5,416 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
            "Fetched 496 kB in 0s (5,964 kB/s)\n",
            "Selecting previously unselected package python-opengl.\n",
            "(Reading database ... 144487 files and directories currently installed.)\n",
            "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
            "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
            "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,266 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.4 [784 kB]\n",
            "Fetched 784 kB in 0s (8,827 kB/s)\n",
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 146842 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n",
            "Collecting EasyProcess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
            "Successfully installed EasyProcess-0.3 pyvirtualdisplay-1.3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f7f5e2b6710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT_SbbFT2fRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GAME = \"Breakout-v4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkS7YkbOvzzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def ipython_show_video(path):\n",
        "    \"\"\"Show a video at `path` within IPython Notebook\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(path):\n",
        "        raise NameError(\"Cannot access: {}\".format(path))\n",
        "\n",
        "    video = io.open(path, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "\n",
        "    display(HTML(\n",
        "        data=\"\"\"\n",
        "        <video alt=\"test\" controls>\n",
        "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "        </video>\n",
        "        \"\"\".format(encoded.decode('ascii'))\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sOrzSI_qdLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "from datetime import datetime\n",
        "\n",
        "base_path = '/content'\n",
        "\n",
        "datetime_path = datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
        "\n",
        "model_path = os.path.join(base_path, 'save_model', datetime_path)\n",
        "\n",
        "os.makedirs(model_path, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uweIXwzfgZm",
        "colab_type": "text"
      },
      "source": [
        "### 학습 속도를 높이기 위해 흑백 화면으로 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPKuMtqaupLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 210*160*3(color) --> 84*84(mono)\n",
        "# float --> integer (to reduce the size of replay memory)\n",
        "def pre_processing(observe):\n",
        "    processed_observe = np.uint8(\n",
        "        resize(rgb2gray(observe), (84, 84), mode='constant') * 255)\n",
        "    return processed_observe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBRF3oDsmai6",
        "colab_type": "text"
      },
      "source": [
        "### Agent 클래스 정의\n",
        "* 하이퍼파라미터  \n",
        "  * epsilon : 탐색을 위한 확률정보 값\n",
        "  * epsilon_start, self.epsilon_end : 입실론 값의 범위 \n",
        "  * exploration_steps : 입실론 값을 감소시킬 단계\n",
        "  * epsilon_decay_step : 한번에 감소시킬 입실론 크기\n",
        "  * batch_size : 배치 사이즈\n",
        "  * train_start : 학습 시작 메모리 길이\n",
        "  * update_target_rate : 타겟 네트워크를 업데이트 시킬 step\n",
        "  * discount_factor : 감가율\n",
        "  * memory : 학습정보를 담기위한 메모리 객체\n",
        "  * no_op_steps : 30 스텝 이후 학습정보를 모으기 위한 설정값\n",
        "* 함수\n",
        "  * optimizer(self) : Huber Loss를 이용한 최적화 함수 정의\n",
        "  * build_model(self) : 상태가 입력, 큐함수가 출력인 모델 생성\n",
        "  * update_target_model(self) : 타겟 모델을 모델의 가중치로 업데이트\n",
        "  * get_action(self, history) : 입실론 탐욕 정책으로 행동 선택\n",
        "  * remember(self, history, action, reward, next_history, dead) : 샘플 <s,a,r,s'>을 리플레이 메모리에 저장\n",
        "  * train_replay(self) : 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
        "  * save_model(self, name): 학습 모델 저장\n",
        "  * load_model(self, filename): 학습 모델 로드\n",
        "  * setup_summary(self): 각 에피소드당 학습 정보를 기록"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9RoSWl9vCyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, action_size, model_load=False):\n",
        "        self.render = False\n",
        "        self.load_model = False\n",
        "        # 상태와 행동의 크기 정의\n",
        "        self.state_size = (84, 84, 4)\n",
        "        self.action_size = action_size\n",
        "        # DQN 하이퍼파라미터 정의\n",
        "        self.epsilon = 1.\n",
        "        self.epsilon_start, self.epsilon_end = 1.0, 0.1\n",
        "        self.exploration_steps = 10.\n",
        "        self.epsilon_decay_step = (self.epsilon_start - self.epsilon_end) \\\n",
        "                                  / self.exploration_steps\n",
        "        # 학습을 위한 파라미터 정의\n",
        "        self.batch_size = 32\n",
        "        self.train_start = 50000\n",
        "        self.update_target_rate = 10000\n",
        "        self.discount_factor = 0.99\n",
        "        self.memory = deque(maxlen=400000)\n",
        "        self.no_op_steps = 30\n",
        "\n",
        "        # 모델과 타겟 모델을 생성하고 타겟 모델을 초기화\n",
        "        self.model = self.build_model()\n",
        "        self.target_model = self.build_model()\n",
        "        self.update_target_model()\n",
        "\n",
        "        self.optimizer = self.optimizer()\n",
        "\n",
        "        self.sess = tf.InteractiveSession()\n",
        "        K.set_session(self.sess)\n",
        "\n",
        "        self.avg_q_max, self.avg_loss = 0, 0\n",
        "        self.summary_placeholders, self.update_ops, self.summary_op = \\\n",
        "            self.setup_summary()\n",
        "        \n",
        "        tbc=TensorBoardColab()\n",
        "        \n",
        "        self.summary_writer = tbc.get_writer()\n",
        "        self.summary_writer = tf.summary.FileWriter(\n",
        "            './Graph', self.sess.graph)\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        if self.load_model:\n",
        "            self.model.load_weights(os.path.join(model_path, \"breakout_dqn.h5\"))\n",
        "\n",
        "    # Huber Loss를 이용한 최적화 함수 정의\n",
        "    def optimizer(self):\n",
        "        a = K.placeholder(shape=(None,), dtype='int32')\n",
        "        y = K.placeholder(shape=(None,), dtype='float32')\n",
        "\n",
        "        py_x = self.model.output\n",
        "\n",
        "        a_one_hot = K.one_hot(a, self.action_size)\n",
        "        q_value = K.sum(py_x * a_one_hot, axis=1)\n",
        "        \n",
        "        loss = huber_loss(labels=y, predictions=q_value)\n",
        "\n",
        "        optimizer = RMSprop(lr=0.00025, epsilon=0.01)\n",
        "        updates = optimizer.get_updates(loss, self.model.trainable_weights)\n",
        "        train = K.function([self.model.input, a, y], [loss], updates=updates)\n",
        "\n",
        "        return train\n",
        "\n",
        "    # 상태가 입력, 큐함수가 출력인 모델 생성\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu',\n",
        "                         input_shape=self.state_size))\n",
        "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
        "        model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dense(self.action_size))\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "    # 타겟 모델을 모델의 가중치로 업데이트\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    # 입실론 탐욕 정책으로 행동 선택\n",
        "    def get_action(self, history):\n",
        "        history = np.float32(history / 255.0)\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        else:\n",
        "            q_value = self.model.predict(history)\n",
        "            return np.argmax(q_value[0])\n",
        "\n",
        "    # 샘플 <s,a,r,s'>을 리플레이 메모리에 저장\n",
        "    def remember(self, history, action, reward, next_history, dead):\n",
        "        self.memory.append((history, action, reward, next_history, dead))\n",
        "\n",
        "    # 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습\n",
        "    def train_replay(self):\n",
        "        if len(self.memory) < self.train_start:\n",
        "            return\n",
        "        if self.epsilon > self.epsilon_end:\n",
        "            self.epsilon -= self.epsilon_decay_step\n",
        "\n",
        "        mini_batch = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "        history = np.zeros((self.batch_size, self.state_size[0],\n",
        "                            self.state_size[1], self.state_size[2]))\n",
        "        next_history = np.zeros((self.batch_size, self.state_size[0],\n",
        "                                 self.state_size[1], self.state_size[2]))\n",
        "        target = np.zeros((self.batch_size,))\n",
        "        action, reward, dead = [], [], []\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            history[i] = np.float32(mini_batch[i][0] / 255.)\n",
        "            next_history[i] = np.float32(mini_batch[i][3] / 255.)\n",
        "            action.append(mini_batch[i][1])\n",
        "            reward.append(mini_batch[i][2])\n",
        "            dead.append(mini_batch[i][4])\n",
        "\n",
        "        target_value = self.target_model.predict(next_history)\n",
        "\n",
        "        # 타겟 모델에서 s' 상태에서의 최대 Q 함수 값을 가져옴\n",
        "        for i in range(self.batch_size):\n",
        "            if dead[i]:\n",
        "                target[i] = reward[i]\n",
        "            else:\n",
        "                target[i] = reward[i] + self.discount_factor * np.amax(target_value[i])\n",
        "\n",
        "        loss = self.optimizer([history, action, target])\n",
        "        self.avg_loss += loss[0]\n",
        "\n",
        "    def save_model(self, name):\n",
        "        self.model.save_weights(name)\n",
        "    \n",
        "    def load_model(self, filename):\n",
        "        self.model.load_weights(filename)\n",
        "\n",
        "    # 각 에피소드당 학습 정보를 기록\n",
        "    def setup_summary(self):\n",
        "        episode_total_reward = tf.Variable(0.)\n",
        "        episode_avg_max_q = tf.Variable(0.)\n",
        "        episode_duration = tf.Variable(0.)\n",
        "        episode_avg_loss = tf.Variable(0.)\n",
        "\n",
        "        tf.summary.scalar('Total_Reward/Episode', episode_total_reward)\n",
        "        tf.summary.scalar('Average_Max_Q/Episode', episode_avg_max_q)\n",
        "        tf.summary.scalar('Duration/Episode', episode_duration)\n",
        "        tf.summary.scalar('Average_Loss/Episode', episode_avg_loss)\n",
        "\n",
        "        summary_vars = [episode_total_reward, episode_avg_max_q,\n",
        "                        episode_duration, episode_avg_loss]\n",
        "        summary_placeholders = [tf.placeholder(tf.float32) for _ in\n",
        "                                range(len(summary_vars))]\n",
        "        update_ops = [summary_vars[i].assign(summary_placeholders[i]) for i in\n",
        "                      range(len(summary_vars))]\n",
        "        summary_op = tf.summary.merge_all()\n",
        "        return summary_placeholders, update_ops, summary_op"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJKHy75Uzkhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPISODES = 50000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWRLX2kVvKin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62d0dd76-36b6-4e7f-a5d5-e43bca9b327e"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from gym import wrappers\n",
        "    \n",
        "    # breakout 게임 환경 생성\n",
        "    env = gym.make('BreakoutDeterministic-v4')\n",
        "\n",
        "    # colab(모니터가 없는 서버)에서 게임 시행을 위한 모니터 래퍼 추가\n",
        "    env = wrappers.Monitor(env, f\"/tmp/{GAME}\", force=True)\n",
        "    \n",
        "    # DQN agent 객체 생성\n",
        "    agent = DQNAgent(action_size=3)\n",
        "\n",
        "    scores, episodes, global_step = [], [], 0\n",
        "\n",
        "    for e in range(EPISODES):\n",
        "        done = False\n",
        "        dead = False\n",
        "        \n",
        "        # 1 episode = 5 lives\n",
        "        step, score, start_life = 0, 0, 5\n",
        "        observe = env.reset()\n",
        "\n",
        "        # 30 no-op(30 타임세텝 동안 에이전트는 정지)\n",
        "        for _ in range(random.randint(1, agent.no_op_steps)):\n",
        "            observe, _, _, _ = env.step(1)\n",
        "\n",
        "        # 에피소드 시작시 이전 프레임이 없으므로\n",
        "        # 초기 상태를 복사하여 기록 생성\n",
        "        state = pre_processing(observe)\n",
        "        history = np.stack((state, state, state, state), axis=2)\n",
        "        history = np.reshape([history], (1, 84, 84, 4))\n",
        "\n",
        "        while not done:\n",
        "            if agent.render:\n",
        "                env.render()\n",
        "            global_step += 1\n",
        "            step += 1\n",
        "\n",
        "            # 바로 전 4개의 상태로 행동을 선택\n",
        "            action = agent.get_action(history)\n",
        "            \n",
        "            # 1: 정지/ 2: 왼쪽/ 3: 오른쪽\n",
        "            if action == 0:\n",
        "                real_action = 1\n",
        "            elif action == 1:\n",
        "                real_action = 2\n",
        "            else:\n",
        "                real_action = 3\n",
        "\n",
        "            # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
        "            observe, reward, done, info = env.step(real_action)\n",
        "\n",
        "            # 매 스텝 마다 관찰된 상태(이미지) 전처리\n",
        "            next_state = pre_processing(observe)\n",
        "            next_state = np.reshape([next_state], (1, 84, 84, 1))\n",
        "            next_history = np.append(next_state, history[:, :, :, :3], axis=3)\n",
        "\n",
        "            agent.avg_q_max += np.amax(\n",
        "                agent.model.predict(np.float32(history / 255.))[0])\n",
        "\n",
        "            # 에이전트가 공을 놓치면 dead --> 에피소드는 종료되지 않음\n",
        "            if start_life > info['ale.lives']:\n",
        "                dead = True\n",
        "                start_life = info['ale.lives']\n",
        "\n",
        "            reward = np.clip(reward, -1., 1.)\n",
        "\n",
        "            # 샘플 <s, a, r, s'>을 리플레이 메모리에 저장 후 학습\n",
        "            agent.remember(history, action, reward, next_history, dead)\n",
        "            agent.train_replay()\n",
        "            \n",
        "            # 일정 시간마다 타깃 모델을 모델의 가중치로 업데이트\n",
        "            if global_step % agent.update_target_rate == 0:\n",
        "                agent.update_target_model()\n",
        "\n",
        "            score += reward\n",
        "\n",
        "            # 에이전트가 dead 면, dead 값 리셋\n",
        "            if dead:\n",
        "                dead = False\n",
        "            else:\n",
        "                history = next_history\n",
        "\n",
        "            # 각 에피스드 마다 학습 정보를 기록\n",
        "            if done:\n",
        "                if global_step > agent.train_start:\n",
        "                    stats = [score, agent.avg_q_max / float(step), step,\n",
        "                             agent.avg_loss / float(step)]\n",
        "                    for i in range(len(stats)):\n",
        "                        agent.sess.run(agent.update_ops[i], feed_dict={\n",
        "                            agent.summary_placeholders[i]: float(stats[i])\n",
        "                        })\n",
        "                    summary_str = agent.sess.run(agent.summary_op)\n",
        "                    agent.summary_writer.add_summary(summary_str, e + 1)\n",
        "\n",
        "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
        "                      len(agent.memory), \"  epsilon:\", agent.epsilon,\n",
        "                      \"  global_step:\", global_step, \"  average_q:\",\n",
        "                      agent.avg_q_max / float(step), \"  average loss:\",\n",
        "                      agent.avg_loss / float(step))\n",
        "\n",
        "                agent.avg_q_max, agent.avg_loss = 0, 0\n",
        "\n",
        "        # 1000 에피소드마다 모델 저장\n",
        "        if e % 100 == 0:\n",
        "            agent.model.save_weights(os.path.join(model_path, \"breakout_dqn.h5\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 20, 20, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 9, 9, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,685,667\n",
            "Trainable params: 1,685,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 20, 20, 32)        8224      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 64)          32832     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 1,685,667\n",
            "Trainable params: 1,685,667\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://9dc5e053556a.ngrok.io\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "episode: 0   score: 2.0   memory length: 205   epsilon: 1.0   global_step: 205   average_q: 0.04793911605346494   average loss: 0.0\n",
            "episode: 1   score: 1.0   memory length: 370   epsilon: 1.0   global_step: 370   average_q: 0.0496840960148609   average loss: 0.0\n",
            "episode: 2   score: 3.0   memory length: 615   epsilon: 1.0   global_step: 615   average_q: 0.04510334929337307   average loss: 0.0\n",
            "episode: 3   score: 2.0   memory length: 811   epsilon: 1.0   global_step: 811   average_q: 0.04619120895786553   average loss: 0.0\n",
            "episode: 4   score: 0.0   memory length: 917   epsilon: 1.0   global_step: 917   average_q: 0.049181762625867466   average loss: 0.0\n",
            "episode: 5   score: 3.0   memory length: 1158   epsilon: 1.0   global_step: 1158   average_q: 0.04840655668147867   average loss: 0.0\n",
            "episode: 6   score: 1.0   memory length: 1332   epsilon: 1.0   global_step: 1332   average_q: 0.0480524224453959   average loss: 0.0\n",
            "episode: 7   score: 2.0   memory length: 1529   epsilon: 1.0   global_step: 1529   average_q: 0.05099217081206099   average loss: 0.0\n",
            "episode: 8   score: 2.0   memory length: 1749   epsilon: 1.0   global_step: 1749   average_q: 0.047019070386886595   average loss: 0.0\n",
            "episode: 9   score: 1.0   memory length: 1908   epsilon: 1.0   global_step: 1908   average_q: 0.047779251264888536   average loss: 0.0\n",
            "episode: 10   score: 1.0   memory length: 2064   epsilon: 1.0   global_step: 2064   average_q: 0.047265139480049796   average loss: 0.0\n",
            "episode: 11   score: 0.0   memory length: 2192   epsilon: 1.0   global_step: 2192   average_q: 0.04977982159471139   average loss: 0.0\n",
            "episode: 12   score: 2.0   memory length: 2386   epsilon: 1.0   global_step: 2386   average_q: 0.0473767304312937   average loss: 0.0\n",
            "episode: 13   score: 1.0   memory length: 2546   epsilon: 1.0   global_step: 2546   average_q: 0.046986924461089076   average loss: 0.0\n",
            "episode: 14   score: 1.0   memory length: 2694   epsilon: 1.0   global_step: 2694   average_q: 0.04931600057092067   average loss: 0.0\n",
            "episode: 15   score: 4.0   memory length: 2948   epsilon: 1.0   global_step: 2948   average_q: 0.056243390754217235   average loss: 0.0\n",
            "episode: 16   score: 1.0   memory length: 3099   epsilon: 1.0   global_step: 3099   average_q: 0.05108488393046998   average loss: 0.0\n",
            "episode: 17   score: 0.0   memory length: 3199   epsilon: 1.0   global_step: 3199   average_q: 0.049437542743980885   average loss: 0.0\n",
            "episode: 18   score: 2.0   memory length: 3405   epsilon: 1.0   global_step: 3405   average_q: 0.04735172431445816   average loss: 0.0\n",
            "episode: 19   score: 2.0   memory length: 3584   epsilon: 1.0   global_step: 3584   average_q: 0.05044532750405413   average loss: 0.0\n",
            "episode: 20   score: 3.0   memory length: 3811   epsilon: 1.0   global_step: 3811   average_q: 0.0420816137500534   average loss: 0.0\n",
            "episode: 21   score: 0.0   memory length: 3923   epsilon: 1.0   global_step: 3923   average_q: 0.0491473250357168   average loss: 0.0\n",
            "episode: 22   score: 2.0   memory length: 4110   epsilon: 1.0   global_step: 4110   average_q: 0.04902827104224878   average loss: 0.0\n",
            "episode: 23   score: 4.0   memory length: 4347   epsilon: 1.0   global_step: 4347   average_q: 0.05169992436525188   average loss: 0.0\n",
            "episode: 24   score: 0.0   memory length: 4463   epsilon: 1.0   global_step: 4463   average_q: 0.049537871450442694   average loss: 0.0\n",
            "episode: 25   score: 0.0   memory length: 4583   epsilon: 1.0   global_step: 4583   average_q: 0.04915391259516279   average loss: 0.0\n",
            "episode: 26   score: 1.0   memory length: 4738   epsilon: 1.0   global_step: 4738   average_q: 0.0477082769236257   average loss: 0.0\n",
            "episode: 27   score: 2.0   memory length: 4914   epsilon: 1.0   global_step: 4914   average_q: 0.05299689847213978   average loss: 0.0\n",
            "episode: 28   score: 0.0   memory length: 5036   epsilon: 1.0   global_step: 5036   average_q: 0.049780363858234686   average loss: 0.0\n",
            "episode: 29   score: 0.0   memory length: 5134   epsilon: 1.0   global_step: 5134   average_q: 0.049942864675302893   average loss: 0.0\n",
            "episode: 30   score: 2.0   memory length: 5330   epsilon: 1.0   global_step: 5330   average_q: 0.048596441137547394   average loss: 0.0\n",
            "episode: 31   score: 1.0   memory length: 5475   epsilon: 1.0   global_step: 5475   average_q: 0.050399191831720286   average loss: 0.0\n",
            "episode: 32   score: 1.0   memory length: 5619   epsilon: 1.0   global_step: 5619   average_q: 0.04772601374942395   average loss: 0.0\n",
            "episode: 33   score: 1.0   memory length: 5787   epsilon: 1.0   global_step: 5787   average_q: 0.04799763315046827   average loss: 0.0\n",
            "episode: 34   score: 0.0   memory length: 5890   epsilon: 1.0   global_step: 5890   average_q: 0.0495247145011587   average loss: 0.0\n",
            "episode: 35   score: 2.0   memory length: 6084   epsilon: 1.0   global_step: 6084   average_q: 0.04900093662754162   average loss: 0.0\n",
            "episode: 36   score: 3.0   memory length: 6315   epsilon: 1.0   global_step: 6315   average_q: 0.049787698289403666   average loss: 0.0\n",
            "episode: 37   score: 1.0   memory length: 6467   epsilon: 1.0   global_step: 6467   average_q: 0.04980544047430158   average loss: 0.0\n",
            "episode: 38   score: 2.0   memory length: 6650   epsilon: 1.0   global_step: 6650   average_q: 0.047375016484429926   average loss: 0.0\n",
            "episode: 39   score: 4.0   memory length: 6912   epsilon: 1.0   global_step: 6912   average_q: 0.053524114973558724   average loss: 0.0\n",
            "episode: 40   score: 1.0   memory length: 7053   epsilon: 1.0   global_step: 7053   average_q: 0.05035034247429658   average loss: 0.0\n",
            "episode: 41   score: 1.0   memory length: 7199   epsilon: 1.0   global_step: 7199   average_q: 0.04759278355089769   average loss: 0.0\n",
            "episode: 42   score: 0.0   memory length: 7305   epsilon: 1.0   global_step: 7305   average_q: 0.04924342753189915   average loss: 0.0\n",
            "episode: 43   score: 0.0   memory length: 7422   epsilon: 1.0   global_step: 7422   average_q: 0.04960191367655738   average loss: 0.0\n",
            "episode: 44   score: 1.0   memory length: 7575   epsilon: 1.0   global_step: 7575   average_q: 0.049152156350269816   average loss: 0.0\n",
            "episode: 45   score: 2.0   memory length: 7747   epsilon: 1.0   global_step: 7747   average_q: 0.04885407818784548   average loss: 0.0\n",
            "episode: 46   score: 1.0   memory length: 7915   epsilon: 1.0   global_step: 7915   average_q: 0.050216486832747854   average loss: 0.0\n",
            "episode: 47   score: 0.0   memory length: 8015   epsilon: 1.0   global_step: 8015   average_q: 0.04960828334093094   average loss: 0.0\n",
            "episode: 48   score: 6.0   memory length: 8330   epsilon: 1.0   global_step: 8330   average_q: 0.0457333202518168   average loss: 0.0\n",
            "episode: 49   score: 1.0   memory length: 8457   epsilon: 1.0   global_step: 8457   average_q: 0.04998299552817044   average loss: 0.0\n",
            "episode: 50   score: 2.0   memory length: 8632   epsilon: 1.0   global_step: 8632   average_q: 0.04891844104443278   average loss: 0.0\n",
            "episode: 51   score: 2.0   memory length: 8810   epsilon: 1.0   global_step: 8810   average_q: 0.04883456320156542   average loss: 0.0\n",
            "episode: 52   score: 1.0   memory length: 8961   epsilon: 1.0   global_step: 8961   average_q: 0.047840160545923854   average loss: 0.0\n",
            "episode: 53   score: 1.0   memory length: 9115   epsilon: 1.0   global_step: 9115   average_q: 0.04825067967660241   average loss: 0.0\n",
            "episode: 54   score: 0.0   memory length: 9220   epsilon: 1.0   global_step: 9220   average_q: 0.04926435173976989   average loss: 0.0\n",
            "episode: 55   score: 2.0   memory length: 9416   epsilon: 1.0   global_step: 9416   average_q: 0.04780549375454382   average loss: 0.0\n",
            "episode: 56   score: 3.0   memory length: 9665   epsilon: 1.0   global_step: 9665   average_q: 0.047818954899368514   average loss: 0.0\n",
            "episode: 57   score: 2.0   memory length: 9848   epsilon: 1.0   global_step: 9848   average_q: 0.04905077605381038   average loss: 0.0\n",
            "episode: 58   score: 3.0   memory length: 10112   epsilon: 1.0   global_step: 10112   average_q: 0.05003403276769501   average loss: 0.0\n",
            "episode: 59   score: 0.0   memory length: 10216   epsilon: 1.0   global_step: 10216   average_q: 0.0496961845156665   average loss: 0.0\n",
            "episode: 60   score: 2.0   memory length: 10411   epsilon: 1.0   global_step: 10411   average_q: 0.050613385305190696   average loss: 0.0\n",
            "episode: 61   score: 1.0   memory length: 10574   epsilon: 1.0   global_step: 10574   average_q: 0.04790784951093738   average loss: 0.0\n",
            "episode: 62   score: 0.0   memory length: 10676   epsilon: 1.0   global_step: 10676   average_q: 0.049348483263861896   average loss: 0.0\n",
            "episode: 63   score: 0.0   memory length: 10794   epsilon: 1.0   global_step: 10794   average_q: 0.048795477502931985   average loss: 0.0\n",
            "episode: 64   score: 1.0   memory length: 10959   epsilon: 1.0   global_step: 10959   average_q: 0.049690990962765434   average loss: 0.0\n",
            "episode: 65   score: 3.0   memory length: 11202   epsilon: 1.0   global_step: 11202   average_q: 0.04656795294257839   average loss: 0.0\n",
            "episode: 66   score: 0.0   memory length: 11317   epsilon: 1.0   global_step: 11317   average_q: 0.04948839211593504   average loss: 0.0\n",
            "episode: 67   score: 0.0   memory length: 11415   epsilon: 1.0   global_step: 11415   average_q: 0.04927907667445893   average loss: 0.0\n",
            "episode: 68   score: 0.0   memory length: 11545   epsilon: 1.0   global_step: 11545   average_q: 0.04948715160672481   average loss: 0.0\n",
            "episode: 69   score: 0.0   memory length: 11671   epsilon: 1.0   global_step: 11671   average_q: 0.04930447027205475   average loss: 0.0\n",
            "episode: 70   score: 2.0   memory length: 11873   epsilon: 1.0   global_step: 11873   average_q: 0.04734008248415914   average loss: 0.0\n",
            "episode: 71   score: 2.0   memory length: 12077   epsilon: 1.0   global_step: 12077   average_q: 0.04538989996574089   average loss: 0.0\n",
            "episode: 72   score: 3.0   memory length: 12329   epsilon: 1.0   global_step: 12329   average_q: 0.04804295668053248   average loss: 0.0\n",
            "episode: 73   score: 4.0   memory length: 12609   epsilon: 1.0   global_step: 12609   average_q: 0.046162117897932016   average loss: 0.0\n",
            "episode: 74   score: 5.0   memory length: 12901   epsilon: 1.0   global_step: 12901   average_q: 0.04658174907712087   average loss: 0.0\n",
            "episode: 75   score: 0.0   memory length: 13016   epsilon: 1.0   global_step: 13016   average_q: 0.04991795171214187   average loss: 0.0\n",
            "episode: 76   score: 0.0   memory length: 13141   epsilon: 1.0   global_step: 13141   average_q: 0.049226169764995574   average loss: 0.0\n",
            "episode: 77   score: 3.0   memory length: 13353   epsilon: 1.0   global_step: 13353   average_q: 0.047075738076050325   average loss: 0.0\n",
            "episode: 78   score: 0.0   memory length: 13461   epsilon: 1.0   global_step: 13461   average_q: 0.04969685873085702   average loss: 0.0\n",
            "episode: 79   score: 2.0   memory length: 13674   epsilon: 1.0   global_step: 13674   average_q: 0.04627757383064485   average loss: 0.0\n",
            "episode: 80   score: 0.0   memory length: 13795   epsilon: 1.0   global_step: 13795   average_q: 0.049639015127558354   average loss: 0.0\n",
            "episode: 81   score: 1.0   memory length: 13955   epsilon: 1.0   global_step: 13955   average_q: 0.046750888833776115   average loss: 0.0\n",
            "episode: 82   score: 1.0   memory length: 14109   epsilon: 1.0   global_step: 14109   average_q: 0.051394336651284976   average loss: 0.0\n",
            "episode: 83   score: 2.0   memory length: 14300   epsilon: 1.0   global_step: 14300   average_q: 0.04768035414565296   average loss: 0.0\n",
            "episode: 84   score: 2.0   memory length: 14495   epsilon: 1.0   global_step: 14495   average_q: 0.04959756741539026   average loss: 0.0\n",
            "episode: 85   score: 0.0   memory length: 14614   epsilon: 1.0   global_step: 14614   average_q: 0.049601013232179046   average loss: 0.0\n",
            "episode: 86   score: 0.0   memory length: 14727   epsilon: 1.0   global_step: 14727   average_q: 0.04928872114525432   average loss: 0.0\n",
            "episode: 87   score: 0.0   memory length: 14853   epsilon: 1.0   global_step: 14853   average_q: 0.0494599345598429   average loss: 0.0\n",
            "episode: 88   score: 1.0   memory length: 14998   epsilon: 1.0   global_step: 14998   average_q: 0.05034465979913185   average loss: 0.0\n",
            "episode: 89   score: 0.0   memory length: 15127   epsilon: 1.0   global_step: 15127   average_q: 0.04977021083351253   average loss: 0.0\n",
            "episode: 90   score: 2.0   memory length: 15320   epsilon: 1.0   global_step: 15320   average_q: 0.05274574248207048   average loss: 0.0\n",
            "episode: 91   score: 1.0   memory length: 15462   epsilon: 1.0   global_step: 15462   average_q: 0.049234347916404964   average loss: 0.0\n",
            "episode: 92   score: 2.0   memory length: 15633   epsilon: 1.0   global_step: 15633   average_q: 0.04999315394469869   average loss: 0.0\n",
            "episode: 93   score: 3.0   memory length: 15844   epsilon: 1.0   global_step: 15844   average_q: 0.0518050699084291   average loss: 0.0\n",
            "episode: 94   score: 1.0   memory length: 16011   epsilon: 1.0   global_step: 16011   average_q: 0.047934328033003265   average loss: 0.0\n",
            "episode: 95   score: 2.0   memory length: 16227   epsilon: 1.0   global_step: 16227   average_q: 0.046594109317218815   average loss: 0.0\n",
            "episode: 96   score: 1.0   memory length: 16389   epsilon: 1.0   global_step: 16389   average_q: 0.047866820691176405   average loss: 0.0\n",
            "episode: 97   score: 1.0   memory length: 16531   epsilon: 1.0   global_step: 16531   average_q: 0.05082470141875912   average loss: 0.0\n",
            "episode: 98   score: 1.0   memory length: 16656   epsilon: 1.0   global_step: 16656   average_q: 0.04468981698155403   average loss: 0.0\n",
            "episode: 99   score: 4.0   memory length: 16925   epsilon: 1.0   global_step: 16925   average_q: 0.044166180336342425   average loss: 0.0\n",
            "episode: 100   score: 2.0   memory length: 17124   epsilon: 1.0   global_step: 17124   average_q: 0.04773441921152062   average loss: 0.0\n",
            "episode: 101   score: 2.0   memory length: 17278   epsilon: 1.0   global_step: 17278   average_q: 0.05100889905513107   average loss: 0.0\n",
            "episode: 102   score: 0.0   memory length: 17409   epsilon: 1.0   global_step: 17409   average_q: 0.049480375613420065   average loss: 0.0\n",
            "episode: 103   score: 2.0   memory length: 17594   epsilon: 1.0   global_step: 17594   average_q: 0.04756316365422429   average loss: 0.0\n",
            "episode: 104   score: 0.0   memory length: 17693   epsilon: 1.0   global_step: 17693   average_q: 0.04946727975450381   average loss: 0.0\n",
            "episode: 105   score: 1.0   memory length: 17843   epsilon: 1.0   global_step: 17843   average_q: 0.048928658217191695   average loss: 0.0\n",
            "episode: 106   score: 2.0   memory length: 18021   epsilon: 1.0   global_step: 18021   average_q: 0.04466012143268344   average loss: 0.0\n",
            "episode: 107   score: 0.0   memory length: 18134   epsilon: 1.0   global_step: 18134   average_q: 0.049198397723710645   average loss: 0.0\n",
            "episode: 108   score: 1.0   memory length: 18279   epsilon: 1.0   global_step: 18279   average_q: 0.04791228092949966   average loss: 0.0\n",
            "episode: 109   score: 1.0   memory length: 18449   epsilon: 1.0   global_step: 18449   average_q: 0.04815929409335641   average loss: 0.0\n",
            "episode: 110   score: 3.0   memory length: 18685   epsilon: 1.0   global_step: 18685   average_q: 0.048199685053678894   average loss: 0.0\n",
            "episode: 111   score: 1.0   memory length: 18855   epsilon: 1.0   global_step: 18855   average_q: 0.048161573708057404   average loss: 0.0\n",
            "episode: 112   score: 0.0   memory length: 18965   epsilon: 1.0   global_step: 18965   average_q: 0.049815806678750296   average loss: 0.0\n",
            "episode: 113   score: 2.0   memory length: 19166   epsilon: 1.0   global_step: 19166   average_q: 0.047344227075873324   average loss: 0.0\n",
            "episode: 114   score: 2.0   memory length: 19386   epsilon: 1.0   global_step: 19386   average_q: 0.04949024053798481   average loss: 0.0\n",
            "episode: 115   score: 0.0   memory length: 19488   epsilon: 1.0   global_step: 19488   average_q: 0.04958033419268973   average loss: 0.0\n",
            "episode: 116   score: 2.0   memory length: 19697   epsilon: 1.0   global_step: 19697   average_q: 0.049121370744049264   average loss: 0.0\n",
            "episode: 117   score: 2.0   memory length: 19890   epsilon: 1.0   global_step: 19890   average_q: 0.04767701813439631   average loss: 0.0\n",
            "episode: 118   score: 2.0   memory length: 20085   epsilon: 1.0   global_step: 20085   average_q: 0.047770493916976145   average loss: 0.0\n",
            "episode: 119   score: 1.0   memory length: 20240   epsilon: 1.0   global_step: 20240   average_q: 0.049765128377945195   average loss: 0.0\n",
            "episode: 120   score: 0.0   memory length: 20371   epsilon: 1.0   global_step: 20371   average_q: 0.04929879677432184   average loss: 0.0\n",
            "episode: 121   score: 2.0   memory length: 20589   epsilon: 1.0   global_step: 20589   average_q: 0.04758106674486344   average loss: 0.0\n",
            "episode: 122   score: 1.0   memory length: 20759   epsilon: 1.0   global_step: 20759   average_q: 0.04884777020882158   average loss: 0.0\n",
            "episode: 123   score: 2.0   memory length: 20958   epsilon: 1.0   global_step: 20958   average_q: 0.046958946140866785   average loss: 0.0\n",
            "episode: 124   score: 1.0   memory length: 21104   epsilon: 1.0   global_step: 21104   average_q: 0.050469300492781484   average loss: 0.0\n",
            "episode: 125   score: 0.0   memory length: 21218   epsilon: 1.0   global_step: 21218   average_q: 0.04955200148386914   average loss: 0.0\n",
            "episode: 126   score: 1.0   memory length: 21391   epsilon: 1.0   global_step: 21391   average_q: 0.049254494444655544   average loss: 0.0\n",
            "episode: 127   score: 2.0   memory length: 21563   epsilon: 1.0   global_step: 21563   average_q: 0.048798862758070924   average loss: 0.0\n",
            "episode: 128   score: 0.0   memory length: 21689   epsilon: 1.0   global_step: 21689   average_q: 0.0496973768172283   average loss: 0.0\n",
            "episode: 129   score: 2.0   memory length: 21868   epsilon: 1.0   global_step: 21868   average_q: 0.050818660426572716   average loss: 0.0\n",
            "episode: 130   score: 4.0   memory length: 22120   epsilon: 1.0   global_step: 22120   average_q: 0.04458552618171015   average loss: 0.0\n",
            "episode: 131   score: 2.0   memory length: 22318   epsilon: 1.0   global_step: 22318   average_q: 0.04790616562270155   average loss: 0.0\n",
            "episode: 132   score: 1.0   memory length: 22475   epsilon: 1.0   global_step: 22475   average_q: 0.04953608837476961   average loss: 0.0\n",
            "episode: 133   score: 0.0   memory length: 22584   epsilon: 1.0   global_step: 22584   average_q: 0.04978524104034135   average loss: 0.0\n",
            "episode: 134   score: 3.0   memory length: 22812   epsilon: 1.0   global_step: 22812   average_q: 0.04573081141305074   average loss: 0.0\n",
            "episode: 135   score: 0.0   memory length: 22923   epsilon: 1.0   global_step: 22923   average_q: 0.04961848087810181   average loss: 0.0\n",
            "episode: 136   score: 2.0   memory length: 23118   epsilon: 1.0   global_step: 23118   average_q: 0.04878347453016501   average loss: 0.0\n",
            "episode: 137   score: 2.0   memory length: 23294   epsilon: 1.0   global_step: 23294   average_q: 0.0532021603166041   average loss: 0.0\n",
            "episode: 138   score: 0.0   memory length: 23392   epsilon: 1.0   global_step: 23392   average_q: 0.04957662108449303   average loss: 0.0\n",
            "episode: 139   score: 1.0   memory length: 23539   epsilon: 1.0   global_step: 23539   average_q: 0.05013050800379442   average loss: 0.0\n",
            "episode: 140   score: 1.0   memory length: 23693   epsilon: 1.0   global_step: 23693   average_q: 0.048152724982469114   average loss: 0.0\n",
            "episode: 141   score: 0.0   memory length: 23804   epsilon: 1.0   global_step: 23804   average_q: 0.04964434922681198   average loss: 0.0\n",
            "episode: 142   score: 1.0   memory length: 23967   epsilon: 1.0   global_step: 23967   average_q: 0.04868976182184336   average loss: 0.0\n",
            "episode: 143   score: 2.0   memory length: 24149   epsilon: 1.0   global_step: 24149   average_q: 0.04875190154864238   average loss: 0.0\n",
            "episode: 144   score: 0.0   memory length: 24261   epsilon: 1.0   global_step: 24261   average_q: 0.04973202158829996   average loss: 0.0\n",
            "episode: 145   score: 0.0   memory length: 24374   epsilon: 1.0   global_step: 24374   average_q: 0.049380165747309156   average loss: 0.0\n",
            "episode: 146   score: 1.0   memory length: 24529   epsilon: 1.0   global_step: 24529   average_q: 0.04680256656100673   average loss: 0.0\n",
            "episode: 147   score: 0.0   memory length: 24651   epsilon: 1.0   global_step: 24651   average_q: 0.049628830102623485   average loss: 0.0\n",
            "episode: 148   score: 0.0   memory length: 24764   epsilon: 1.0   global_step: 24764   average_q: 0.049266686217974774   average loss: 0.0\n",
            "episode: 149   score: 0.0   memory length: 24878   epsilon: 1.0   global_step: 24878   average_q: 0.04885221939337881   average loss: 0.0\n",
            "episode: 150   score: 2.0   memory length: 25073   epsilon: 1.0   global_step: 25073   average_q: 0.05004884952153915   average loss: 0.0\n",
            "episode: 151   score: 0.0   memory length: 25185   epsilon: 1.0   global_step: 25185   average_q: 0.04927572002634406   average loss: 0.0\n",
            "episode: 152   score: 1.0   memory length: 25345   epsilon: 1.0   global_step: 25345   average_q: 0.04681549940723926   average loss: 0.0\n",
            "episode: 153   score: 0.0   memory length: 25469   epsilon: 1.0   global_step: 25469   average_q: 0.04952380719083932   average loss: 0.0\n",
            "episode: 154   score: 2.0   memory length: 25658   epsilon: 1.0   global_step: 25658   average_q: 0.04906216699373785   average loss: 0.0\n",
            "episode: 155   score: 1.0   memory length: 25810   epsilon: 1.0   global_step: 25810   average_q: 0.048254842526818574   average loss: 0.0\n",
            "episode: 156   score: 2.0   memory length: 26037   epsilon: 1.0   global_step: 26037   average_q: 0.049580348516088224   average loss: 0.0\n",
            "episode: 157   score: 1.0   memory length: 26180   epsilon: 1.0   global_step: 26180   average_q: 0.04716397066424777   average loss: 0.0\n",
            "episode: 158   score: 0.0   memory length: 26303   epsilon: 1.0   global_step: 26303   average_q: 0.04957213177065539   average loss: 0.0\n",
            "episode: 159   score: 2.0   memory length: 26495   epsilon: 1.0   global_step: 26495   average_q: 0.05035012048513939   average loss: 0.0\n",
            "episode: 160   score: 3.0   memory length: 26723   epsilon: 1.0   global_step: 26723   average_q: 0.04838200746790359   average loss: 0.0\n",
            "episode: 161   score: 1.0   memory length: 26859   epsilon: 1.0   global_step: 26859   average_q: 0.04959614353035303   average loss: 0.0\n",
            "episode: 162   score: 2.0   memory length: 27037   epsilon: 1.0   global_step: 27037   average_q: 0.05096174117303296   average loss: 0.0\n",
            "episode: 163   score: 0.0   memory length: 27140   epsilon: 1.0   global_step: 27140   average_q: 0.048670124985928674   average loss: 0.0\n",
            "episode: 164   score: 3.0   memory length: 27356   epsilon: 1.0   global_step: 27356   average_q: 0.0448833667949118   average loss: 0.0\n",
            "episode: 165   score: 1.0   memory length: 27490   epsilon: 1.0   global_step: 27490   average_q: 0.04852070828983143   average loss: 0.0\n",
            "episode: 166   score: 2.0   memory length: 27677   epsilon: 1.0   global_step: 27677   average_q: 0.04526476350856975   average loss: 0.0\n",
            "episode: 167   score: 1.0   memory length: 27825   epsilon: 1.0   global_step: 27825   average_q: 0.05040170863975544   average loss: 0.0\n",
            "episode: 168   score: 1.0   memory length: 27977   epsilon: 1.0   global_step: 27977   average_q: 0.04956044249334618   average loss: 0.0\n",
            "episode: 169   score: 0.0   memory length: 28076   epsilon: 1.0   global_step: 28076   average_q: 0.04951108770087512   average loss: 0.0\n",
            "episode: 170   score: 3.0   memory length: 28305   epsilon: 1.0   global_step: 28305   average_q: 0.04758723573067823   average loss: 0.0\n",
            "episode: 171   score: 0.0   memory length: 28419   epsilon: 1.0   global_step: 28419   average_q: 0.04925969216907233   average loss: 0.0\n",
            "episode: 172   score: 2.0   memory length: 28596   epsilon: 1.0   global_step: 28596   average_q: 0.04469236603143525   average loss: 0.0\n",
            "episode: 173   score: 1.0   memory length: 28751   epsilon: 1.0   global_step: 28751   average_q: 0.04904665773914706   average loss: 0.0\n",
            "episode: 174   score: 2.0   memory length: 28928   epsilon: 1.0   global_step: 28928   average_q: 0.04866901414710923   average loss: 0.0\n",
            "episode: 175   score: 2.0   memory length: 29116   epsilon: 1.0   global_step: 29116   average_q: 0.04518947439228601   average loss: 0.0\n",
            "episode: 176   score: 0.0   memory length: 29240   epsilon: 1.0   global_step: 29240   average_q: 0.04907778061686024   average loss: 0.0\n",
            "episode: 177   score: 2.0   memory length: 29414   epsilon: 1.0   global_step: 29414   average_q: 0.0480023180616313   average loss: 0.0\n",
            "episode: 178   score: 3.0   memory length: 29618   epsilon: 1.0   global_step: 29618   average_q: 0.04852603080079836   average loss: 0.0\n",
            "episode: 179   score: 2.0   memory length: 29807   epsilon: 1.0   global_step: 29807   average_q: 0.045412693271245905   average loss: 0.0\n",
            "episode: 180   score: 3.0   memory length: 30039   epsilon: 1.0   global_step: 30039   average_q: 0.04817767489444593   average loss: 0.0\n",
            "episode: 181   score: 0.0   memory length: 30144   epsilon: 1.0   global_step: 30144   average_q: 0.049407032025711874   average loss: 0.0\n",
            "episode: 182   score: 2.0   memory length: 30331   epsilon: 1.0   global_step: 30331   average_q: 0.04747330931259349   average loss: 0.0\n",
            "episode: 183   score: 1.0   memory length: 30475   epsilon: 1.0   global_step: 30475   average_q: 0.04942005694222947   average loss: 0.0\n",
            "episode: 184   score: 0.0   memory length: 30569   epsilon: 1.0   global_step: 30569   average_q: 0.04947686869096249   average loss: 0.0\n",
            "episode: 185   score: 2.0   memory length: 30742   epsilon: 1.0   global_step: 30742   average_q: 0.044139115279809585   average loss: 0.0\n",
            "episode: 186   score: 1.0   memory length: 30892   epsilon: 1.0   global_step: 30892   average_q: 0.04920170605182648   average loss: 0.0\n",
            "episode: 187   score: 2.0   memory length: 31093   epsilon: 1.0   global_step: 31093   average_q: 0.044987481383986734   average loss: 0.0\n",
            "episode: 188   score: 0.0   memory length: 31210   epsilon: 1.0   global_step: 31210   average_q: 0.05003032002311487   average loss: 0.0\n",
            "episode: 189   score: 0.0   memory length: 31321   epsilon: 1.0   global_step: 31321   average_q: 0.049781260156148185   average loss: 0.0\n",
            "episode: 190   score: 2.0   memory length: 31500   epsilon: 1.0   global_step: 31500   average_q: 0.04453560035654952   average loss: 0.0\n",
            "episode: 191   score: 3.0   memory length: 31740   epsilon: 1.0   global_step: 31740   average_q: 0.04747419242436687   average loss: 0.0\n",
            "episode: 192   score: 2.0   memory length: 31946   epsilon: 1.0   global_step: 31946   average_q: 0.047946360179232164   average loss: 0.0\n",
            "episode: 193   score: 3.0   memory length: 32165   epsilon: 1.0   global_step: 32165   average_q: 0.04530501372465804   average loss: 0.0\n",
            "episode: 194   score: 1.0   memory length: 32332   epsilon: 1.0   global_step: 32332   average_q: 0.04793909018089671   average loss: 0.0\n",
            "episode: 195   score: 4.0   memory length: 32612   epsilon: 1.0   global_step: 32612   average_q: 0.04560968991635101   average loss: 0.0\n",
            "episode: 196   score: 2.0   memory length: 32822   epsilon: 1.0   global_step: 32822   average_q: 0.049726709492859386   average loss: 0.0\n",
            "episode: 197   score: 1.0   memory length: 32972   epsilon: 1.0   global_step: 32972   average_q: 0.049432036876678465   average loss: 0.0\n",
            "episode: 198   score: 1.0   memory length: 33123   epsilon: 1.0   global_step: 33123   average_q: 0.04946306320709108   average loss: 0.0\n",
            "episode: 199   score: 1.0   memory length: 33274   epsilon: 1.0   global_step: 33274   average_q: 0.050095714061268115   average loss: 0.0\n",
            "episode: 200   score: 0.0   memory length: 33377   epsilon: 1.0   global_step: 33377   average_q: 0.0496185708393171   average loss: 0.0\n",
            "episode: 201   score: 2.0   memory length: 33546   epsilon: 1.0   global_step: 33546   average_q: 0.044804142270038816   average loss: 0.0\n",
            "episode: 202   score: 0.0   memory length: 33666   epsilon: 1.0   global_step: 33666   average_q: 0.04967986981694897   average loss: 0.0\n",
            "episode: 203   score: 2.0   memory length: 33879   epsilon: 1.0   global_step: 33879   average_q: 0.047815186806687726   average loss: 0.0\n",
            "episode: 204   score: 1.0   memory length: 34035   epsilon: 1.0   global_step: 34035   average_q: 0.05043378142783275   average loss: 0.0\n",
            "episode: 205   score: 1.0   memory length: 34177   epsilon: 1.0   global_step: 34177   average_q: 0.049836392579993734   average loss: 0.0\n",
            "episode: 206   score: 0.0   memory length: 34301   epsilon: 1.0   global_step: 34301   average_q: 0.049699988546631026   average loss: 0.0\n",
            "episode: 207   score: 0.0   memory length: 34417   epsilon: 1.0   global_step: 34417   average_q: 0.04987433610548233   average loss: 0.0\n",
            "episode: 208   score: 1.0   memory length: 34588   epsilon: 1.0   global_step: 34588   average_q: 0.04905121196170299   average loss: 0.0\n",
            "episode: 209   score: 2.0   memory length: 34786   epsilon: 1.0   global_step: 34786   average_q: 0.04497375041998998   average loss: 0.0\n",
            "episode: 210   score: 0.0   memory length: 34898   epsilon: 1.0   global_step: 34898   average_q: 0.049906336868714006   average loss: 0.0\n",
            "episode: 211   score: 0.0   memory length: 35000   epsilon: 1.0   global_step: 35000   average_q: 0.04963558634706572   average loss: 0.0\n",
            "episode: 212   score: 3.0   memory length: 35207   epsilon: 1.0   global_step: 35207   average_q: 0.04937291091334992   average loss: 0.0\n",
            "episode: 213   score: 1.0   memory length: 35372   epsilon: 1.0   global_step: 35372   average_q: 0.04896590210723154   average loss: 0.0\n",
            "episode: 214   score: 3.0   memory length: 35624   epsilon: 1.0   global_step: 35624   average_q: 0.04654657193237827   average loss: 0.0\n",
            "episode: 215   score: 3.0   memory length: 35834   epsilon: 1.0   global_step: 35834   average_q: 0.0493228361365341   average loss: 0.0\n",
            "episode: 216   score: 1.0   memory length: 35980   epsilon: 1.0   global_step: 35980   average_q: 0.05006009044304286   average loss: 0.0\n",
            "episode: 217   score: 0.0   memory length: 36089   epsilon: 1.0   global_step: 36089   average_q: 0.04928514781758326   average loss: 0.0\n",
            "episode: 218   score: 1.0   memory length: 36231   epsilon: 1.0   global_step: 36231   average_q: 0.050760959576762896   average loss: 0.0\n",
            "episode: 219   score: 1.0   memory length: 36382   epsilon: 1.0   global_step: 36382   average_q: 0.05071306300183006   average loss: 0.0\n",
            "episode: 220   score: 2.0   memory length: 36578   epsilon: 1.0   global_step: 36578   average_q: 0.047834010414627134   average loss: 0.0\n",
            "episode: 221   score: 1.0   memory length: 36727   epsilon: 1.0   global_step: 36727   average_q: 0.04812775409761691   average loss: 0.0\n",
            "episode: 222   score: 0.0   memory length: 36853   epsilon: 1.0   global_step: 36853   average_q: 0.04989422458623137   average loss: 0.0\n",
            "episode: 223   score: 0.0   memory length: 36959   epsilon: 1.0   global_step: 36959   average_q: 0.049365342014803075   average loss: 0.0\n",
            "episode: 224   score: 3.0   memory length: 37187   epsilon: 1.0   global_step: 37187   average_q: 0.050939210804930905   average loss: 0.0\n",
            "episode: 225   score: 2.0   memory length: 37399   epsilon: 1.0   global_step: 37399   average_q: 0.0492008973510479   average loss: 0.0\n",
            "episode: 226   score: 2.0   memory length: 37586   epsilon: 1.0   global_step: 37586   average_q: 0.04875656115737828   average loss: 0.0\n",
            "episode: 227   score: 0.0   memory length: 37711   epsilon: 1.0   global_step: 37711   average_q: 0.049609220445156095   average loss: 0.0\n",
            "episode: 228   score: 1.0   memory length: 37844   epsilon: 1.0   global_step: 37844   average_q: 0.049198082879297715   average loss: 0.0\n",
            "episode: 229   score: 2.0   memory length: 38019   epsilon: 1.0   global_step: 38019   average_q: 0.04686306453176907   average loss: 0.0\n",
            "episode: 230   score: 1.0   memory length: 38160   epsilon: 1.0   global_step: 38160   average_q: 0.04765103226329418   average loss: 0.0\n",
            "episode: 231   score: 0.0   memory length: 38259   epsilon: 1.0   global_step: 38259   average_q: 0.04924189088621525   average loss: 0.0\n",
            "episode: 232   score: 3.0   memory length: 38463   epsilon: 1.0   global_step: 38463   average_q: 0.04659417012304652   average loss: 0.0\n",
            "episode: 233   score: 1.0   memory length: 38608   epsilon: 1.0   global_step: 38608   average_q: 0.04781492653078046   average loss: 0.0\n",
            "episode: 234   score: 1.0   memory length: 38732   epsilon: 1.0   global_step: 38732   average_q: 0.05088811154447256   average loss: 0.0\n",
            "episode: 235   score: 0.0   memory length: 38862   epsilon: 1.0   global_step: 38862   average_q: 0.04977018967843973   average loss: 0.0\n",
            "episode: 236   score: 1.0   memory length: 39002   epsilon: 1.0   global_step: 39002   average_q: 0.0504832819636379   average loss: 0.0\n",
            "episode: 237   score: 1.0   memory length: 39186   epsilon: 1.0   global_step: 39186   average_q: 0.04959971729018118   average loss: 0.0\n",
            "episode: 238   score: 1.0   memory length: 39343   epsilon: 1.0   global_step: 39343   average_q: 0.047976878987755746   average loss: 0.0\n",
            "episode: 239   score: 2.0   memory length: 39543   epsilon: 1.0   global_step: 39543   average_q: 0.04515391264110804   average loss: 0.0\n",
            "episode: 240   score: 2.0   memory length: 39739   epsilon: 1.0   global_step: 39739   average_q: 0.04763940242784364   average loss: 0.0\n",
            "episode: 241   score: 1.0   memory length: 39926   epsilon: 1.0   global_step: 39926   average_q: 0.047440043545980505   average loss: 0.0\n",
            "episode: 242   score: 0.0   memory length: 40047   epsilon: 1.0   global_step: 40047   average_q: 0.04951407187733768   average loss: 0.0\n",
            "episode: 243   score: 0.0   memory length: 40147   epsilon: 1.0   global_step: 40147   average_q: 0.04909572489559651   average loss: 0.0\n",
            "episode: 244   score: 0.0   memory length: 40242   epsilon: 1.0   global_step: 40242   average_q: 0.049135960913018174   average loss: 0.0\n",
            "episode: 245   score: 0.0   memory length: 40364   epsilon: 1.0   global_step: 40364   average_q: 0.04927855104085852   average loss: 0.0\n",
            "episode: 246   score: 2.0   memory length: 40545   epsilon: 1.0   global_step: 40545   average_q: 0.04726170178358726   average loss: 0.0\n",
            "episode: 247   score: 0.0   memory length: 40668   epsilon: 1.0   global_step: 40668   average_q: 0.04976251139873412   average loss: 0.0\n",
            "episode: 248   score: 1.0   memory length: 40809   epsilon: 1.0   global_step: 40809   average_q: 0.04946801343813856   average loss: 0.0\n",
            "episode: 249   score: 2.0   memory length: 40994   epsilon: 1.0   global_step: 40994   average_q: 0.048995978002612656   average loss: 0.0\n",
            "episode: 250   score: 3.0   memory length: 41245   epsilon: 1.0   global_step: 41245   average_q: 0.045003993518324015   average loss: 0.0\n",
            "episode: 251   score: 1.0   memory length: 41392   epsilon: 1.0   global_step: 41392   average_q: 0.04668565365631564   average loss: 0.0\n",
            "episode: 252   score: 2.0   memory length: 41627   epsilon: 1.0   global_step: 41627   average_q: 0.047998985410370724   average loss: 0.0\n",
            "episode: 253   score: 1.0   memory length: 41784   epsilon: 1.0   global_step: 41784   average_q: 0.04955556469073721   average loss: 0.0\n",
            "episode: 254   score: 0.0   memory length: 41901   epsilon: 1.0   global_step: 41901   average_q: 0.049507061035459876   average loss: 0.0\n",
            "episode: 255   score: 2.0   memory length: 42113   epsilon: 1.0   global_step: 42113   average_q: 0.04815743343447739   average loss: 0.0\n",
            "episode: 256   score: 0.0   memory length: 42228   epsilon: 1.0   global_step: 42228   average_q: 0.04979258263888566   average loss: 0.0\n",
            "episode: 257   score: 2.0   memory length: 42413   epsilon: 1.0   global_step: 42413   average_q: 0.04496845598961856   average loss: 0.0\n",
            "episode: 258   score: 2.0   memory length: 42632   epsilon: 1.0   global_step: 42632   average_q: 0.047884436315733546   average loss: 0.0\n",
            "episode: 259   score: 0.0   memory length: 42740   epsilon: 1.0   global_step: 42740   average_q: 0.04974687865210904   average loss: 0.0\n",
            "episode: 260   score: 4.0   memory length: 43038   epsilon: 1.0   global_step: 43038   average_q: 0.048909405271378936   average loss: 0.0\n",
            "episode: 261   score: 1.0   memory length: 43197   epsilon: 1.0   global_step: 43197   average_q: 0.049961990530385914   average loss: 0.0\n",
            "episode: 262   score: 0.0   memory length: 43314   epsilon: 1.0   global_step: 43314   average_q: 0.04971061678778412   average loss: 0.0\n",
            "episode: 263   score: 0.0   memory length: 43430   epsilon: 1.0   global_step: 43430   average_q: 0.04948872947615796   average loss: 0.0\n",
            "episode: 264   score: 4.0   memory length: 43676   epsilon: 1.0   global_step: 43676   average_q: 0.04524105116422099   average loss: 0.0\n",
            "episode: 265   score: 0.0   memory length: 43822   epsilon: 1.0   global_step: 43822   average_q: 0.04970490177200265   average loss: 0.0\n",
            "episode: 266   score: 1.0   memory length: 43978   epsilon: 1.0   global_step: 43978   average_q: 0.05046401082132107   average loss: 0.0\n",
            "episode: 267   score: 0.0   memory length: 44094   epsilon: 1.0   global_step: 44094   average_q: 0.04860381101225984   average loss: 0.0\n",
            "episode: 268   score: 0.0   memory length: 44208   epsilon: 1.0   global_step: 44208   average_q: 0.04968116174272278   average loss: 0.0\n",
            "episode: 269   score: 1.0   memory length: 44332   epsilon: 1.0   global_step: 44332   average_q: 0.04867510152079405   average loss: 0.0\n",
            "episode: 270   score: 0.0   memory length: 44432   epsilon: 1.0   global_step: 44432   average_q: 0.04943766392767429   average loss: 0.0\n",
            "episode: 271   score: 1.0   memory length: 44609   epsilon: 1.0   global_step: 44609   average_q: 0.048219959993483656   average loss: 0.0\n",
            "episode: 272   score: 2.0   memory length: 44820   epsilon: 1.0   global_step: 44820   average_q: 0.04772642389010479   average loss: 0.0\n",
            "episode: 273   score: 0.0   memory length: 44935   epsilon: 1.0   global_step: 44935   average_q: 0.04863149122051571   average loss: 0.0\n",
            "episode: 274   score: 3.0   memory length: 45173   epsilon: 1.0   global_step: 45173   average_q: 0.04562990910553632   average loss: 0.0\n",
            "episode: 275   score: 0.0   memory length: 45303   epsilon: 1.0   global_step: 45303   average_q: 0.04943439272733835   average loss: 0.0\n",
            "episode: 276   score: 2.0   memory length: 45490   epsilon: 1.0   global_step: 45490   average_q: 0.0494572584203539   average loss: 0.0\n",
            "episode: 277   score: 2.0   memory length: 45661   epsilon: 1.0   global_step: 45661   average_q: 0.04468477491224021   average loss: 0.0\n",
            "episode: 278   score: 0.0   memory length: 45793   epsilon: 1.0   global_step: 45793   average_q: 0.04959454398715135   average loss: 0.0\n",
            "episode: 279   score: 2.0   memory length: 45986   epsilon: 1.0   global_step: 45986   average_q: 0.04763231812517878   average loss: 0.0\n",
            "episode: 280   score: 0.0   memory length: 46119   epsilon: 1.0   global_step: 46119   average_q: 0.0498805479111528   average loss: 0.0\n",
            "episode: 281   score: 2.0   memory length: 46296   epsilon: 1.0   global_step: 46296   average_q: 0.0489131292843886   average loss: 0.0\n",
            "episode: 282   score: 1.0   memory length: 46444   epsilon: 1.0   global_step: 46444   average_q: 0.04805094781457572   average loss: 0.0\n",
            "episode: 283   score: 2.0   memory length: 46613   epsilon: 1.0   global_step: 46613   average_q: 0.05078091582603003   average loss: 0.0\n",
            "episode: 284   score: 1.0   memory length: 46747   epsilon: 1.0   global_step: 46747   average_q: 0.04977092964213286   average loss: 0.0\n",
            "episode: 285   score: 0.0   memory length: 46872   epsilon: 1.0   global_step: 46872   average_q: 0.04930756649374962   average loss: 0.0\n",
            "episode: 286   score: 0.0   memory length: 46976   epsilon: 1.0   global_step: 46976   average_q: 0.04939935456674833   average loss: 0.0\n",
            "episode: 287   score: 2.0   memory length: 47155   epsilon: 1.0   global_step: 47155   average_q: 0.04463708046927799   average loss: 0.0\n",
            "episode: 288   score: 2.0   memory length: 47339   epsilon: 1.0   global_step: 47339   average_q: 0.050942609248601875   average loss: 0.0\n",
            "episode: 289   score: 0.0   memory length: 47435   epsilon: 1.0   global_step: 47435   average_q: 0.0487119296255211   average loss: 0.0\n",
            "episode: 290   score: 2.0   memory length: 47626   epsilon: 1.0   global_step: 47626   average_q: 0.048705874566788446   average loss: 0.0\n",
            "episode: 291   score: 1.0   memory length: 47761   epsilon: 1.0   global_step: 47761   average_q: 0.04996863200708672   average loss: 0.0\n",
            "episode: 292   score: 1.0   memory length: 47923   epsilon: 1.0   global_step: 47923   average_q: 0.04677225837920919   average loss: 0.0\n",
            "episode: 293   score: 1.0   memory length: 48088   epsilon: 1.0   global_step: 48088   average_q: 0.049199781341083125   average loss: 0.0\n",
            "episode: 294   score: 1.0   memory length: 48247   epsilon: 1.0   global_step: 48247   average_q: 0.04841804663715123   average loss: 0.0\n",
            "episode: 295   score: 3.0   memory length: 48475   epsilon: 1.0   global_step: 48475   average_q: 0.047821358777582645   average loss: 0.0\n",
            "episode: 296   score: 2.0   memory length: 48659   epsilon: 1.0   global_step: 48659   average_q: 0.04675397738490416   average loss: 0.0\n",
            "episode: 297   score: 2.0   memory length: 48829   epsilon: 1.0   global_step: 48829   average_q: 0.05083742700517178   average loss: 0.0\n",
            "episode: 298   score: 3.0   memory length: 49069   epsilon: 1.0   global_step: 49069   average_q: 0.04963069556591412   average loss: 0.0\n",
            "episode: 299   score: 0.0   memory length: 49168   epsilon: 1.0   global_step: 49168   average_q: 0.04923866136056004   average loss: 0.0\n",
            "episode: 300   score: 0.0   memory length: 49295   epsilon: 1.0   global_step: 49295   average_q: 0.04968796300841129   average loss: 0.0\n",
            "episode: 301   score: 3.0   memory length: 49526   epsilon: 1.0   global_step: 49526   average_q: 0.051294207073006276   average loss: 0.0\n",
            "episode: 302   score: 0.0   memory length: 49633   epsilon: 1.0   global_step: 49633   average_q: 0.04908807255397333   average loss: 0.0\n",
            "episode: 303   score: 0.0   memory length: 49753   epsilon: 1.0   global_step: 49753   average_q: 0.04925233563408256   average loss: 0.0\n",
            "episode: 304   score: 0.0   memory length: 49858   epsilon: 1.0   global_step: 49858   average_q: 0.049493415015084405   average loss: 0.0\n",
            "episode: 305   score: 0.0   memory length: 49968   epsilon: 1.0   global_step: 49968   average_q: 0.04948850077661601   average loss: 0.0\n",
            "episode: 306   score: 1.0   memory length: 50172   epsilon: 0.010000000000000259   global_step: 50172   average_q: 0.9711859857700035   average loss: 0.33372605198395583\n",
            "episode: 307   score: 2.0   memory length: 50511   epsilon: 0.010000000000000259   global_step: 50511   average_q: 1.1040341543764491   average loss: 0.3712157161181792\n",
            "episode: 308   score: 4.0   memory length: 50809   epsilon: 0.010000000000000259   global_step: 50809   average_q: 1.0951275975512178   average loss: 0.3884153993054472\n",
            "episode: 309   score: 3.0   memory length: 51101   epsilon: 0.010000000000000259   global_step: 51101   average_q: 1.0146561748769185   average loss: 0.3683864280033625\n",
            "episode: 310   score: 2.0   memory length: 51545   epsilon: 0.010000000000000259   global_step: 51545   average_q: 1.1691797813316722   average loss: 0.34421187665875225\n",
            "episode: 311   score: 0.0   memory length: 51700   epsilon: 0.010000000000000259   global_step: 51700   average_q: 1.1188151928686327   average loss: 0.39797698481982685\n",
            "episode: 312   score: 2.0   memory length: 51942   epsilon: 0.010000000000000259   global_step: 51942   average_q: 1.0860572467165546   average loss: 0.34487017161949146\n",
            "episode: 313   score: 2.0   memory length: 52315   epsilon: 0.010000000000000259   global_step: 52315   average_q: 1.1401010289908096   average loss: 0.3542873993630623\n",
            "episode: 314   score: 3.0   memory length: 52544   epsilon: 0.010000000000000259   global_step: 52544   average_q: 0.9507331943147568   average loss: 0.3354760082952274\n",
            "episode: 315   score: 3.0   memory length: 52803   epsilon: 0.010000000000000259   global_step: 52803   average_q: 1.0379026180068498   average loss: 0.328760354527383\n",
            "episode: 316   score: 3.0   memory length: 53053   epsilon: 0.010000000000000259   global_step: 53053   average_q: 1.080821697950363   average loss: 0.3696920611785026\n",
            "episode: 317   score: 4.0   memory length: 53872   epsilon: 0.010000000000000259   global_step: 53872   average_q: 1.0613276829649678   average loss: 0.340064739762564\n",
            "episode: 318   score: 6.0   memory length: 54509   epsilon: 0.010000000000000259   global_step: 54509   average_q: 1.0481706660246737   average loss: 0.337828800052636\n",
            "episode: 319   score: 2.0   memory length: 54799   epsilon: 0.010000000000000259   global_step: 54799   average_q: 1.0586802659363581   average loss: 0.3410862577285586\n",
            "episode: 320   score: 1.0   memory length: 54970   epsilon: 0.010000000000000259   global_step: 54970   average_q: 1.1337658351624917   average loss: 0.3548187286065747\n",
            "episode: 321   score: 0.0   memory length: 55072   epsilon: 0.010000000000000259   global_step: 55072   average_q: 0.8821031626533059   average loss: 0.383743233922538\n",
            "episode: 322   score: 4.0   memory length: 55438   epsilon: 0.010000000000000259   global_step: 55438   average_q: 1.108094461465794   average loss: 0.34019318384412706\n",
            "episode: 323   score: 1.0   memory length: 55584   epsilon: 0.010000000000000259   global_step: 55584   average_q: 1.0965885079070314   average loss: 0.34261966828570034\n",
            "episode: 324   score: 3.0   memory length: 55956   epsilon: 0.010000000000000259   global_step: 55956   average_q: 1.071974957021334   average loss: 0.34620553158107403\n",
            "episode: 325   score: 5.0   memory length: 56464   epsilon: 0.010000000000000259   global_step: 56464   average_q: 1.087666567385666   average loss: 0.35143445363322606\n",
            "episode: 326   score: 0.0   memory length: 56797   epsilon: 0.010000000000000259   global_step: 56797   average_q: 1.1429940198992823   average loss: 0.34697026460610497\n",
            "episode: 327   score: 2.0   memory length: 57271   epsilon: 0.010000000000000259   global_step: 57271   average_q: 1.0663510403804135   average loss: 0.3553865294299573\n",
            "episode: 328   score: 2.0   memory length: 57701   epsilon: 0.010000000000000259   global_step: 57701   average_q: 1.0639953092087147   average loss: 0.3529724676074048\n",
            "episode: 329   score: 3.0   memory length: 58259   epsilon: 0.010000000000000259   global_step: 58259   average_q: 1.066656835403921   average loss: 0.33462169476771175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwfi__sWvMdM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestAgent:\n",
        "    def __init__(self, action_size):\n",
        "        self.state_size = (84, 84, 4)\n",
        "        self.action_size = action_size\n",
        "        self.no_op_steps = 20\n",
        "\n",
        "        self.model = self.build_model()\n",
        "\n",
        "        self.sess = tf.InteractiveSession()\n",
        "        K.set_session(self.sess)\n",
        "\n",
        "        self.avg_q_max, self.avg_loss = 0, 0\n",
        "        self.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    def build_model(self):\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(32, (8, 8), strides=(4, 4), activation='relu',\n",
        "                         input_shape=self.state_size))\n",
        "        model.add(Conv2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
        "        model.add(Conv2D(64, (3, 3), strides=(1, 1), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dense(self.action_size))\n",
        "        model.summary()\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_action(self, history):\n",
        "        if np.random.random() < 0.01:\n",
        "            return random.randrange(3)\n",
        "        history = np.float32(history / 255.0)\n",
        "        q_value = self.model.predict(history)\n",
        "        return np.argmax(q_value[0])\n",
        "\n",
        "    def load_model(self, filename):\n",
        "        self.model.load_weights(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNaYYaxIvrRU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_EPISODES = 10\n",
        "model_to_load = os.path.join(model_path, 'breakout_dqn.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zhRFRSnL8Jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST_EPISODES = 10\n",
        "link = \"https://drive.google.com/open?id=1RbNmbp8EBXDom3MhhoWezdLNxY3xGPHL\"\n",
        "fluff, id = link.split('=')\n",
        "gdd.download_file_from_google_drive(file_id=id,\n",
        "                                    dest_path='./model_trained.h5')\n",
        "model_to_load = 'model_trained.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLnkOyASM1IR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6dbdd68-c1df-4a9d-8eaf-e24c1a5fdfac"
      },
      "source": [
        "model_to_load"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_trained.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GtqWr3kvPvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from gym import wrappers\n",
        "    \n",
        "    # add virtual monitor for capturing video\n",
        "    env = gym.make('BreakoutDeterministic-v4')\n",
        "    env = wrappers.Monitor(env, f\"/tmp/BreakoutDeterministic-v4\", force=True)\n",
        "  \n",
        "    agent = TestAgent(action_size=3)\n",
        "    agent.load_model(model_to_load)\n",
        "\n",
        "    for e in range(TEST_EPISODES):\n",
        "        done = False\n",
        "        dead = False\n",
        "       \n",
        "        step, score, start_life = 0, 0, 5\n",
        "        observe = env.reset()\n",
        "\n",
        "        for _ in range(random.randint(1, agent.no_op_steps)):\n",
        "            observe, _, _, _ = env.step(1)\n",
        "\n",
        "        state = pre_processing(observe)\n",
        "        history = np.stack((state, state, state, state), axis=2)\n",
        "        history = np.reshape([history], (1, 84, 84, 4))\n",
        "\n",
        "        while not done:\n",
        "            env.render()\n",
        "            step += 1\n",
        "\n",
        "            action = agent.get_action(history)\n",
        "\n",
        "            if action == 0:\n",
        "                real_action = 1\n",
        "            elif action == 1:\n",
        "                real_action = 2\n",
        "            else:\n",
        "                real_action = 3\n",
        "\n",
        "            if dead:\n",
        "                real_action = 1\n",
        "                dead = False\n",
        "\n",
        "            observe, reward, done, info = env.step(real_action)\n",
        "\n",
        "            next_state = pre_processing(observe)\n",
        "            next_state = np.reshape([next_state], (1, 84, 84, 1))\n",
        "            next_history = np.append(next_state, history[:, :, :, :3], axis=3)\n",
        "\n",
        "            if start_life > info['ale.lives']:\n",
        "                dead = True\n",
        "                start_life = info['ale.lives']\n",
        "\n",
        "            score += reward\n",
        " \n",
        "            history = next_history\n",
        "\n",
        "            if done:\n",
        "                print(\"episode:\", e, \"  score:\", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIItIH4czFF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /tmp/BreakoutDeterministic-v4 -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvhadlO-zLpt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "b3348337-968c-432b-ef73-3afb4e7b9dca"
      },
      "source": [
        "ipython_show_video(\"/tmp/BreakoutDeterministic-v4/openaigym.video.1.1084.video000008.mp4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <video alt=\"test\" controls>\n",
              "        <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "        </video>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkGvDIqY0hYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ebe71d7f-6484-42be-b806-ded1b1b13e54"
      },
      "source": [
        "agent.epsilon, agent.epsilon_decay_step, agent.epsilon_end"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 0.09, 0.1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7MhZv-C1rzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}